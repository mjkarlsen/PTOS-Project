---
title: "Predicting Fasciotomy"
output: html_notebook
---

```{r}
pacman::p_load(doParallel, 
               tensorflow)

# install_tensorflow()
```



```{r creating_upsample_model}
patient_list <- patient_periods %>%
  filter.(
    fltr_procedure == T,
    sex != "U"
    # peds_adult_flag == "Peds"
  ) %>%
  select.(
    id,
    fltr_fasciotomy,
    peds_adult_flag,
    fltr_procedure,
    sex,
    race,
    age_in_yrs,
    age_grp,
    injury_desc,
    patient_county,
    cause_of_injury_e_code, 
    place_of_injury
  ) %>%
  distinct()


patient_list <- patient_list %>% 
  left_join.(patient_df, by = "id") %>%
  distinct()


fx_proc_df <- trans_full_df %>%
  filter.(data_source %in% c(
    "diagnosis",
    "procedure",
    "complication"
  )) %>%
  mutate.(data_source = fct_relevel(data_source, c(
    "diagnosis",
    "procedure",
    "complication"
  ))) %>%
  inner_join.(patient_list, by = "id") %>%
  arrange.(id, date, data_source, time) %>%
  mutate.(index = seq_len(.N), by = id) %>%
  mutate.(fltr_fasciotomy = as_factor(fltr_fasciotomy)) %>% 
  select.(index, id, everything.())

clean_df <- fx_proc_df


fx_proc_df <- fx_proc_df %>%
  filter.(
    chapter_desc != "Extremity Compartment Syndrome (not present on admission)",
    code_cd != "83.14"
  ) %>%
  select.(
    id,
    fltr_fasciotomy,
    code_desc,
    subchapter_desc,
    sex,
    race,
    # injury_desc,
    # age_grp,
    age_in_yrs, 
    cause_of_injury_e_code, 
    place_of_injury 
    # admission_gcs_eye, 
    # admission_gcs_verbal, 
    # admission_gcs_motor 
  ) %>%
  as_tibble() %>%
  na.omit()

```

## Upsample Data

```{r randomforest_model}

set.seed(123)
train_test_split <- rsample::initial_split(data = fx_proc_df, 
                                           strata = fltr_fasciotomy, 
                                           prop = 1/2)


train_df <- train_test_split %>% training() 
test_df  <- train_test_split %>% testing()


train_df %>% summarise.(cnt = n.())
test_df %>% summarise.(cnt = n.())

data_balanced_over <- ovun.sample(fltr_fasciotomy ~ .,  #-id -index,
                                  data = train_df,
                                  method = "both",
                                  p = 0.5,
                                  N = 20000,
                                  seed = 123)$data

rf_recipe <- 
  recipe(fltr_fasciotomy ~ ., -id, data = data_balanced_over) %>%
  update_role(fltr_fasciotomy, new_role = "outcome") %>% 
  update_role(id, new_role = "ID") %>% 
  step_other(all_predictors(), -id, threshold = 0.001) %>%
  step_dummy(all_predictors(), -all_outcomes(), -id) %>%
  step_zv(all_nominal(), -id) %>% 
  step_naomit(all_predictors()) 
  

train_data <- prep(rf_recipe) %>% juice() 

test_data <- prep(rf_recipe) %>% bake(test_df) %>% na.omit()

full_data <- prep(rf_recipe) %>% bake(fx_proc_df)


train_data %>% 
  summarize.(cnt = n.(), by = fltr_fasciotomy)


test_data %>% 
  summarize.(cnt = n.(), by = fltr_fasciotomy)


full_data %>% 
  summarize.(cnt = n.(), by = fltr_fasciotomy)


dfs<- list("full_data")
file_path <- 'E:/Northwestern/12 - Capstone/PTOS_Data/'

for(d in dfs) {
    save(list=d, file=paste0(file_path,d, ".RData"))
}


```


```{r message=FALSE, warning=FALSE}

## RANDOM FOREST
rf_model <- rand_forest() %>%
  set_mode("classification") %>%
  set_engine("ranger", verbose = TRUE, importance = "impurity", num.threads = 6) %>%
  fit(fltr_fasciotomy ~ . -id, data = train_data)

# XGBoost on important words only
xgb_model <- boost_tree(mtry = .7,
                        trees = 200,
                        learn_rate = .02,
                        loss_reduction = 0,
                        tree_depth = 20, 
                        sample_size = 1
  ) %>%
  set_mode("classification") %>%
  set_engine("xgboost", nthread = 6) %>%
  fit(fltr_fasciotomy ~ . -id, data = train_data)

## LOGISTIC REGRESSION
glm_model <-
  logistic_reg(mode = "classification") %>%
  set_engine("glm") %>%
  fit(fltr_fasciotomy ~ . -id, data = train_data)

## NEURAL NETWORK
set.seed(579)
nnet_model <- mlp(epochs = 100, hidden_units = 5, dropout = 0.1) %>%
  set_mode("classification") %>%
  # Also set engine-specific `verbose` argument to prevent logging the results:
  set_engine("keras", verbose = 0) %>%
  fit(fltr_fasciotomy ~ . -id, data = train_data)

## RIDGE
ridge_model <- logistic_reg(penalty = tune(), mixture = tune()) %>% # Specify hyperparameters to "tune"
  set_engine("glmnet")

best_parameters <- ridge_model %>%
  tune_grid(fltr_fasciotomy ~ . -id,
            resamples = vfold_cv(train_data, 5), # Specify folds
            grid = expand_grid(penalty = c(0, .1, 1, 10, 1000), # Specify grid to tune
                               mixture = c(0, .2, .4, .8))) %>%
  select_best(metric = "roc_auc") # Extract best parameters based on a metric

ridge_model <- ridge_model %>%
  finalize_model(best_parameters) %>% # Update model with best parameters
  fit(fltr_fasciotomy ~ . -id, data = train_data) # Fit model using best parameters


```

```{r save_model_outputs}


# save the model to disk
saveRDS(rf_model, "E:/Northwestern/12 - Capstone/PTOS_Data/rf_model.rds")
saveRDS(xgb_model, "E:/Northwestern/12 - Capstone/PTOS_Data/xgb_model.rds")
saveRDS(glm_model, "E:/Northwestern/12 - Capstone/PTOS_Data/glm_model.rds")
saveRDS(nnet_model, "E:/Northwestern/12 - Capstone/PTOS_Data/nnet_model.rds")
saveRDS(ridge_model, "E:/Northwestern/12 - Capstone/PTOS_Data/ridge_model.rds")


```


```{r prediction_results}

# Get predictions
train_pred_df <- train_data %>% 
  select(fltr_fasciotomy) %>%
  bind_cols(predict(rf_model, train_data) %>% rename(rf = .pred_class),
            predict(xgb_model, train_data) %>% rename(xgb = .pred_class),
            predict(glm_model, train_data) %>% rename(glm = .pred_class),
            predict(nnet_model, train_data) %>% rename(nnet = .pred_class),
            predict(ridge_model, train_data) %>% rename(ridge = .pred_class)
            )

# Get predictions
test_pred_df <- test_data %>%
  select(fltr_fasciotomy) %>%
  bind_cols(predict(rf_model, test_data) %>% rename(rf = .pred_class),
            predict(xgb_model, test_data) %>% rename(xgb = .pred_class),
            predict(glm_model, test_data) %>% rename(glm = .pred_class),
            predict(nnet_model, test_data) %>% rename(nnet = .pred_class),
            predict(ridge_model, test_data) %>% rename(ridge = .pred_class)
            )


# Check accuracy
train_accuracy_results <- train_pred_df %>%
  pivot_longer(-fltr_fasciotomy, names_to = "model", values_to = "pred") %>%
  group_by(model) %>%
  summarize( f_score = f_meas_vec(fltr_fasciotomy, pred), 
             true_positive = ppv_vec(fltr_fasciotomy, pred),
             false_positive = npv_vec(fltr_fasciotomy, pred), 
             sensitivity = sensitivity_vec(fltr_fasciotomy, pred),
             specificity = specificity_vec(fltr_fasciotomy, pred),
             # prevalance = detection_prevalence_vec(fltr_fasciotomy, pred),
             # recall = recall_vec(fltr_fasciotomy, pred),
             precision = precision_vec(fltr_fasciotomy, pred))%>% 
  arrange(f_score)



# Check accuracy
test_accuracy_results <- test_pred_df %>%
  pivot_longer(-fltr_fasciotomy, names_to = "model", values_to = "pred") %>%
  group_by(model) %>%
  summarize(f_score = f_meas_vec(fltr_fasciotomy, pred), 
            true_positive = ppv_vec(fltr_fasciotomy, pred),
            false_positive = npv_vec(fltr_fasciotomy, pred), 
            sensitivity = sensitivity_vec(fltr_fasciotomy, pred),
            specificity = specificity_vec(fltr_fasciotomy, pred),
            # prevalance = detection_prevalence_vec(fltr_fasciotomy, pred),
            # recall = recall_vec(fltr_fasciotomy, pred),
            precision = precision_vec(fltr_fasciotomy, pred)
            ) %>% 
  arrange(f_score)
```


```{r build_viz_for_presentation}

gt_train_graph <- train_accuracy_results %>% 
  gt() %>% 
    tab_header(title = md("In-Sample Model Accuracy"),
               subtitle = md("Fasciotomy ~ .")) %>% 
  cols_width(everything() ~ px(100)) %>%
  fmt_percent(columns = vars(f_score, true_positive, false_positive, sensitivity, specificity, precision), 
              decimals = 1)

gt_train_graph %>% 
  gtsave(paste0(expr(gt_train_graph),".png") , expand = 10,
    path = paste0(getwd(),"/images/")
  )

gt_test_graph <- test_accuracy_results %>% 
  gt() %>% 
    tab_header(title = md("Out-of-Sample Model Accuracy"),
               subtitle = md("Fasciotomy ~ .")) %>% 
  cols_width(everything() ~ px(100)) %>%
  fmt_percent(columns = vars(f_score, true_positive, false_positive, sensitivity, specificity, precision), 
              decimals = 1)

gt_test_graph %>% 
  gtsave(paste0(expr(gt_test_graph),".png") , expand = 10,
    path = paste0(getwd(),"/images/")
  )


```





# Results from Shiny Application

```{r}

rf_model <- readRDS(file = 'E:/Northwestern/12 - Capstone/PTOS_Data/rf_model.rds')


rf_pred <-
    predict(rf_model, full_data, type = "prob") %>%
    bind_cols(full_data %>% select(id, fltr_fasciotomy)) %>%
    distinct()

rf_model_results <- rf_pred %>%
    select(id, .pred_FALSE, .pred_TRUE, fltr_fasciotomy) %>%
    summarize.(pred_false = mean(.pred_FALSE),
               pred_true = mean(.pred_TRUE),
               pred_false_max = max(.pred_FALSE),
               pred_true_max = max(.pred_TRUE),
               by = c(id, fltr_fasciotomy)) %>%
    arrange(-pred_true)

patient_rf <- rf_model_results %>%
    inner_join.(patient_df %>%
                    select(id,
                           sex,
                           race,
                           forearm_fx_desc,
                           age_in_yrs,
                           injury_desc,
                           place_of_injury
                    ), by = "id")


dfs<- list("patient_rf")
file_path <- 'E:/Northwestern/12 - Capstone/Project/CS_App2/'

for(d in dfs) {
    save(list=d, file=paste0(file_path,d, ".RData"))
}

```



```{r variable_importance_rf}
# Find important words
importance_df <- rf_model$fit$variable.importance %>%
  enframe(name = "variable", value = "importance") %>%
  mutate(importance = rescale(importance)) %>%
  mutate_if(is.double, ~round(.x, 5)) %>%
  arrange(-importance)

# Get vec of important words
variable_list <- importance_df %>%
  filter(importance > .02) %>%
  arrange(importance) %>%
  pull(variable)

rf_vip <- vip::vip(rf_model$fit,num_features = 15) +
  ggthemes::theme_stata() + 
  scale_x_discrete(labels = function(x) str_wrap(janitor::make_clean_names(sub('.*\\_', '',x),
                                                                           case = "title"), width = 70)) +
  theme(axis.text.y=element_text(angle=0, hjust=1)) +
  labs(title = "Variable Importance for RandomForest")
  
  
  ggsave(filename = "rf_vip.png" ,
         plot = rf_vip, 
         width = 8,
         height = 4,
         dpi = 600, 
         path = paste0(getwd(),"/images/"))


  
  rf_vip
  
```

```{r}

library(precrec)

rf_prediction <- test_pred_df %>% 
  mutate(.act_class = (ifelse(fltr_fasciotomy == T, 1, 0)), 
         .pred_class = (ifelse(rf == T, 1, 0)))

roc_data <- rf_prediction #%>% filter(peds_adult_flag == "Adult")

sscurves <- evalmod(scores = roc_data$.act_class, labels = roc_data$.pred_class )

plot(sscurves)



smcurves <- evalmod(scores = roc_data$.act_class, labels = roc_data$.pred_class, x_bins = 100)

autoplot(smcurves)

aucs <- evalmod(scores = roc_data$.act_class, labels = roc_data$.pred_class, mode = 'aucroc')
# Convert to data.frame
aucs.df <- as.data.frame(aucs)

# Use knitr::kable to display the result in a table format
knitr::kable(aucs.df)


auc_ci <- auc_ci(smcurves)

# Use knitr::kable to display the result in a table format
knitr::kable(auc_ci)
```

